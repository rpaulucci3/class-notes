\documentclass[english,openany]{book}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{amssymb,amsmath,listings,parskip}
\usepackage{csquotes}
\MakeOuterQuote{"}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    allcolors=black,
    hidelinks
}

\begin{document}

    \title{Some notes from CS 3600: Intro to Artificial Intelligence}
    \author{Rafael A. O. Paulucci}
    \date{Fall 2019}

    \maketitle

    \tableofcontents

    \lstset{frame=tb,
    showstringspaces=false,
    columns=flexible,
    basicstyle={\small\ttfamily},
    numbers=none,
    breaklines=true,
    breakatwhitespace=true,
    tabsize=4
    }

    \chapter{Introduction}

    \section{Pre-requisites and Logistics}

    $\bullet$ Data structures: lists, graphs, trees...

    $\bullet$ Computational complexity (big O). Most algorithms in the class are NP-hard (verifiable in $O(c^{n})$)

    $\bullet$ Programming: Python 2.7

    \textit{Relation with Machine Learning class: while CS 3600 includes some ML, it is a gentler introduction.}

    $\bullet$ Tests are designed around lectures.

    $\bullet$ There are readings and 4 graded programming assignments (worth 40\% of the final grade).

    $\bullet$ There are 2 exams, each worth 30\% of the final grade. There is no practice exam, but there are practice problems (harder than the exam).

    \section{Some Definitions}

    $\bullet$ Artificial intelligence: study of how to replicate intelligence with computing.

    $\bullet$ Intelligent: an entity is intelligent if it presents behavior that a person would reasonably believe requires intelligence.

    $\bullet$ Turing test: a human "judge" communicates, via teletype, with a computer pretending to be a human and a human pretending to be a computer. If the judge cannot tell the difference, the computer is "intelligent" (assuming the human is intelligent.) This test is not widely used anymore.

    In 1950, Turing predicted that, in 50 years, there would be machines that "fool" judges 30\% of the time.

    $\bullet$ Deception/deflection: a chatbot could say, "I don't understand your message because I'm not a native English speaker. Could you rephrase?"

    $\bullet$ Broad ("strong") AI: emulating humans; beating the Turing test. Being able to do what humans can do.

    $\bullet$ Narrow AI: solving a specific task that was originally done by humans.

    $\bullet$ "Super-human": AI that is able to perform a task better than an expert human.

    $\bullet$ Machine learning (ML): automated discovery of patterns in data and acting on them to make decisions.

    $\bullet$ Deep learning: a class of ML algorithms
    
    \section{A Brief History}
    
    % TODO: fill in
    
    \subsection{Early Automata}
    
    \subsection{Computation}
    
    \subsection{Early AI}
    
    \subsection{Knowledge-based AI}
    
    \chapter{Agents}
    
    \section{Definitions}
    
    $\bullet$ \textbf{Agent}: anything that can perceive the environment through \textbf{sensors} and act on it through \textbf{effectors}.
    
    $\bullet$ \textbf{Agent function}: A mathematical description of an agent's behavior (response to environment) that maps sensory percepts to effector actions.
    
    $\bullet$ \textbf{Agent program}: A concrete implementation of the agent function.
    
    \section{Agent Functions}
    
    $\bullet$ Naively, we could map sensed percepts to specific responses through a table.
    
    $\bullet$ Picture a vampire, whose objective is to suck blood, in a mansion with 2 rooms ($A$ and $B$) side-by-side. The vampire can perform 3 actions: go left, go right, and suck blood.
    
    \begin{tabular}{|c|c|}
        \hline
        Percept & Action\\
        \hline
        ($A$, has people) & Suck\\
        ($A$, is empty) & Go right\\
        ($B$, has people) & Suck\\
        ($B$, is empty) & Go left\\
        \hline
    \end{tabular}
    
    $\bullet$ Problems with this approach: if there are many rooms, the table could be too large to fit in memory. It could even be "infinite", in the case of an "open world."
    
    $\bullet$ A more sophisticated approach is to follow a procedure for writing an agent program:
    
    \begin{enumerate}
        \item Objective function: what is the agent trying to accomplish? Are we succeeding or not?
        \item Actions: how actions can change the world
        \item Sensors: what kinds of percepts are available
        \item Prior knowledge: what information is preloaded into the agent
    \end{enumerate}
    
    $\bullet$ Principle of rationality: Of all my actions, which gets me closer to my objective? I need to choose the "best" action based on what I know.
    
    $\bullet$ For this example, our objective function could be maximizing the number of people whose blood has been sucked.
    
    % TODO: scenarios
    
    \section{Environment Types}
    
    $\bullet$ Fully observable: can sense everything without error.
    
    $\bullet$ Partially observable: can only sense some information due to noise and/or incomplete data.\\
    
    $\bullet$ Deterministic: world changes exactly as desired.
    
    $\bullet$ Stochastic: world has randomness. Uncertain effectors. Action uncertainty and sensor uncertainty.\\
    
    $\bullet$ Discrete: world broken into finite number of chunks.
    
    $\bullet$ Continuous: world has inifnite chunks and graduations of values.\\
    
    $\bullet$ Episodic: prior occurrences do not affect current action choice.
    
    $\bullet$ Sequential: history matters. Current choice of action affects future choices.\\
    
    $\bullet$ Static: changes do not happen while agent is "thinking".
    
    $\bullet$ Dynamic: changes happen while agent is "thinking".\\
    
    $\bullet$ Single-agent: there is only one agent.
    
    $\bullet$ Multi-agent: there are other agents, which can be cooperative or competitive.\\
    
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        & Hanoi & Solitaire & Chess & Pool & Poker & Driving \\
        \hline
        Observability & Fully & Partially & Fully & Fully & Partially & Partially\\
        Determinism & Determ. & Unclear & Unclear & Stoch. & Stoch. & Stoch.\\
        Episodic? & Seq. & Unclear & Seq. & Seq. & Unclear & Seq.\\
        Static? & Static & Static & Static & Static & Static & Dynamic\\
        Discrete? & Discrete & Discrete & Discrete & Cont. & Discrete & Cont.\\
        Agents & Single & Single & Multi & Multi & Multi & Multi\\
        \hline
    \end{tabular}\\
    
    \subsection{Stages of Development}
    
    \begin{enumerate}
        \item Fully observable, deterministic
    
        \item Fully observable, stochastic
    
        \item Partially observable
    
        \item Optimization, machine learning 
    \end{enumerate}
    
    \section{Searching}
    
    $\bullet$ State: unique configuration of the world and relevant facts needed for the agent to make decisions. Includes the environment and the agent itself, in relation to it.
    
    $\bullet$ Initial state: describes the state the agent is in before searching for the solution.
    
    $\bullet$ Goal situation: state(s) that the agent desires to be at (objective function).
    
    $\bullet$ Problem: agent is not at the goal state and doesn't know how to get there. We search when we don't know any other way of getting to the goal.
    
    $\bullet$ Actions: means of transforming the state. Describe transitions between states, according to a set of rules.
    
    $\bullet$ Search problem: find a sequence of actions that transforms the initial state to a state in which the goal situation is recognized.
    
    $\bullet$ Solution: a sequence of actions. If executed, will bring the agent to a goal situation.
    
    $\bullet$ State spaces: set of legal states. Tend to have a large number of states.
    
    $\bullet$ Types of search algorithms: brute-force (uninformed, tries every possible path) and informed (uses prior knowledge.)\\

    $\bullet$ Searching for paths in maps is an example of fully observable, deterministic, sequential, static, discrete scenario.
    
    $\bullet$ States: street intersections (decision points.)
    
    $\bullet$ Actions: taking roads (change the state.)\\
    
    $\bullet$ Another example is an \textit{8-Puzzle}.
    
    Successor function:
    
    % todo: pseudocode
    

\end{document}
