\documentclass[english,openany]{book}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}
\usepackage{babel}
\usepackage{amssymb,amsmath,listings,parskip}
\usepackage{csquotes}
\MakeOuterQuote{"}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    allcolors=black,
    hidelinks
}

\begin{document}

    \title{Some notes from CS 3790: Introduction to Cognitive Science}
    \author{Rafael A. O. Paulucci}
    \date{Fall 2019}

    \maketitle

    \tableofcontents

    \lstset{frame=tb,
    showstringspaces=false,
    columns=flexible,
    basicstyle={\small\ttfamily},
    numbers=none,
    breaklines=true,
    breakatwhitespace=true,
    tabsize=4
    }

    \chapter{Introduction}


\section{Mental Representations}

$\bullet$ The aim of cognitive science is to explain how a mind, human or otherwise, accomplishes daily tasks.

$\bullet$ For example, how does a dog know that it's supposed to meet its owner at the door, with a "sad" face, when it breaks something in the house? How can a marketing specialist determine factors that will bring in new customers?

$\bullet$ Since just looking at a brain provides no answers for those questions, metaphors, analogies and other forms of study are required to assist in understanding the mind.

$\bullet$ Is thinking like computing? Is computing like thinking? We don't know for sure.

$\bullet$ When sensing a landscape (by looking at it), we "decode" elements we see (we know what a sky, road, hill, vineyard etc. look like.) We also ignore what is not useful for analyzing a scene, given the context.

$\bullet$ Perhaps for evolutionary reasons, humans tend to easily recognize faces, as well as attempt to see them in inanimate patterns.

$\bullet$ A non-mental representation is something that can be mapped physically, such as a map.

$\bullet$ A mental representation is a "stand-in" for something that is not in the mind. The world is "outside" the mind. Representations attempt to use some form of "truth" to bring it "inside". Parts of it are rules, concepts, images and analogies.

$\bullet$ Different representations require different procedures. For example, one could ask you to perform a numerical division in Roman numerals. Since most people are used to Arabic numerals, such a calculation would require decoding Roman into Arabic, performing the calculation (in Arabic), and encoding the result back into Roman.\\

\section{History of Cognitive Science}

$\bullet$ Plato: Knowledge is reminiscence. What is known are innate truths.

$\bullet$ Aristotle: Knowledge is rules learned from sensory experience. What is known is empirically derived. "Mind is an unscribed tablet (\textit{tabula rasa)}."\\

$\bullet$ Rationalism: Descartes and Leibniz. Some things are known by intuition; others are deduced by intuition. Some truths are innate.

$\bullet$ Empiricism: Hume and Locke. Our source of knowledge in a subject or its concepts comes strictly from sense experience.

$\bullet$ Empiricism + Rationalism: Immanuel Kant. Faculties of the mind involved in knowing: sensibility and understanding. "Thoughts without concepts are empty."\\

$\bullet$ Experimental psychology: Wilhelm Wundt. Study of mental processes systematically. Knowledge comes from synthesizing representations from what we sense or think. We know when an experience begins and ends.

$\bullet$ Structuralism: Edward Titchener. Study of the structure of the conscious mind. Focus on sensations, images and feelings. "Taxonomy" (inspired by biology) of the structures of mind.

$\bullet$ Functionalism: William James. Influenced by Darwin. Measure functions of mind in terms of adaptation to environment.

$\bullet$ Behaviorism: Watson and Skinner. Only concerned with observable responses to stimuli. (Dominated Western psychology in the early-mid 20th century.)\\

$\bullet$ Computationalism: George Miller. Is the mind like a computer? Humans have mental capabilities for encoding and decoding. Capacity for thinking and short-term memory are limited, but that limitation can be mitigated by encoding information into chunks.

$\bullet$ Dartmouth Conference (1956): John McCarthy, Marvin Minsky, Allen Newell and Herbert Simon. Early artificial intelligence.

$\bullet$ Noam Chomsky: Language is not a learned habit, but an acquired one. We have mental grammars, and an inherited mechanism to acquire languages.

\subsection{Elements of Cognitive Science}

$\bullet$ Material sourced from behavior experiments, computational experiments, grammars and patterns in languages, brain imaging (ablation experiments)...

\chapter{Comparing Mind to a Program}

\section{C.R.U.M.}

\subsection{Definitions}

$\bullet$ \textbf{C.R.U.M.: Computational -- Representational Understanding of Mind.} The Central Hypothesis: thinking can best be understood in terms of representational structures of the mind, and computational procedures that operate on those structures.

$\bullet$ Logical structures: data structures and algorithms are like representations and procedures. Running a program is like thinking.

$\bullet$ Physical structures: neurons and connections for representations are like the "hardware". Neuron firing and activation for procedures are like processors running algorithms.

$\bullet$ Three-way metaphor between mind, brain and computing. Learning something influences how an algorithm could be designed. Learning how a physical structure works influences the understanding of its logical use.

\subsection{Cognitive Science Model}

$\bullet$ Cognitive theory: set of representational structures and set of processes that operate on them.

$\bullet$ Computational model: interpret structures and processes by analogy to computing, its data structures and algorithms.

$\bullet$ Program: implement the model in a programming language.

$\bullet$ Platform: the "hardware".

\subsection{Examples}

\subsubsection{Learning to add}

\begin{enumerate}
    \item Piles of things: counting real-world, tangible objects.

    \item Number system: $1, 2, 3, 4, 5, 6...$

    \item Define concepts such as "larger than" (i.e., in the number system, what appears after is larger; what appears before is not larger)

    \item Map piles of things to this number system. Get things from a pile until they run out, thus mapping the amount of things to a number. (Mistakes such as skipping, double-counting, incorrectly saying a number etc. happen until enough practice has been done.)'

    \item Representation: $1 = \bullet,\ 2 = \bullet \bullet,\ 3 = \bullet \bullet \bullet$. Define the "size of a pile."

    \item Define a symbol for the addition operation: $+$\\ Make it tangible: $\bullet \bullet + \bullet \bullet \bullet = \bullet \bullet \bullet \bullet \bullet$\\
    The idea of "add" is now the same as "combine piles of things."

    \item Introduce the concept of bigger numbers, that cannot be so easily represented in piles: $13 + 28 = ?$

    \item Combine and carry operations: considering each number individually, $(1, 3) + (2, 8) = (3, 11)$. Then, carry: $(3, 11) = (4, 1)$, which is the same as $30 + 11 = 41$.
\end{enumerate}

$\bullet$ Representations: how are numbers represented, especially when we get to numbers larger than $9$?

$\bullet$ Addition could also have been represented as a computer program, with functions such as \textit{vectorize}, \textit{carry}, \textit{reduce} etc.

\subsubsection{Ordering food from a menu}

$\bullet$ Understanding how each word on the menu maps to a tangible ingredient

$\bullet$ Considering the environment/culture you are in, past experiences in ordering (e.g.: McDonald's burger is different from homemade burger; the restaurant I'm in has served me salty food in the past...)

$\bullet$ Making decisions about the price vs. value of each item

$\bullet$ Deciding the most appropriate form of ordering, and encoding the phrase to be said (or the buttons to be pressed.)

\subsection{Iterative Development}

$\bullet$ Theory, model and program affect one another.

$\bullet$ Value of a working program: does it scale (i.e., is it computationally reasonable)? Is it consistent with observed behavior (psychologically plausible)? Can it predict (human) behavior?

\subsection{Evaluation of the Cognitive Model}

Logic, Rules, Concepts, Analogies, Images, Connections.

\subsubsection{Evaluation criteria}

$\bullet$ Representational power: capabilities and efficiency in representing real-world concepts and objects.

$\bullet$ Computational power: abilities in problem solving, learning and language.

$\bullet$ Psychological plausibility: capabilities in accounting for human cognition qualitatively and quantitatively.

$\bullet$ Neurological plausibility: consistency with neurological observations and knowledge of neural architecture.

$\bullet$ Practical applicability: how can it be applied to practical situations (e.g.: teaching, driving, making business decisions...)?

\chapter{Logic}

\section{A Brief History}

$\bullet$ Do people think logically? When do they do so? And about what?

$\bullet$ Is logic the backbone of our thinking?

\subsection{Syllogism}

$\bullet$ Aristotle: syllogism (two premises $\therefore$ one conclusion.)

$\bullet$ Possible premises: all A are B; all A are not B.

$\bullet$ Contingent premises: maybe all A are B; maybe all A are not B; some A are B, some A are not B. \textbf{Those are not allowed under this system.}

$\bullet$ Example: ("All X are Z", "Y is X") $\therefore$ "Y is Z"

$\bullet$ The form admits analysis. What is important is the form, not the content.

\subsection{Logicism}

$\bullet$ Gottlob Frege, Bertrand Russell: all of mathematics is reducible to logic.

$\bullet$ Symbols, axioms, rules of inference, and terms such as "all", "some", "class", "relation".

\subsection{Computationalism}

$\bullet$ Alonzo Church, Alan Turing: what's computable? What's effectively calculable?

$\bullet$ John McCarthy: Artificial Intelligence based on logic.

\section{Formal Logic}

\subsection{Representational Power}

The representational power of formal logic is high, due to the existence of forms below.

\subsubsection{Propositional Logic}

$\bullet$ Propositions can be true of false

$\bullet$ Letters represent atomic statements (e.g.: P: is it raining; Q: it is cloudy.)

$\bullet$ $\neg P$: not P, $P \rightarrow Q$: if P then Q, $P \lor Q$: P or Q, $P \wedge Q$: P and Q

\subsubsection{Modal Logic}

$\bullet$ Keith is happy vs. Keith is \textit{usually} happy

$\bullet$ Qualifying propositions: truth (necessarily, possible, impossible), deontic (obligatory, permissible), epistemic (known), doxastic (believed).

\subsubsection{Predicate Logic}

$\bullet$ Keith is a professor vs. \texttt{is-professor(Keith)}

$\bullet$ Predicates act like truth functions: \texttt{teaches(Keith, CS3790)}

$\bullet$ Quantifiers apply to variables ($\forall, \exists...$)

$\bullet$ Probability functions $P(x)$ assign a value to the truth of a statement $x$, between 0 (false) and 1 (true.)

\subsubsection{Inference}

% TODO: possibly add example for rules of generalization

$\bullet$ \textit{Modus ponens}: "affirms by affirming".
\\If it's raining, then it's cloudy.\\ It's raining.\\ $\therefore$ It's cloudy.

$\bullet$ \textit{Modus tollens}: "denies by denying".
\\If it's raining, then it's cloudy.\\ It's not cloudy.\\ $\therefore$ It's not raining.

$\bullet$ Universal instantiation:\\ All meerkats are mammals.\\ Ralph is a meerkat.\\ $\therefore$ Ralph is a mammal.

$\bullet$ \textbf{Bayes' Rule}: Probability of an outcome is determined by a prior probability and likelihood based on observed data.

$$P (\textrm{hypothesis } | \textrm{ evidence}) = \frac{P(\textrm{evidence } | \textrm{ hypothesis}) \cdot P(\textrm{hypothesis})}{P(\textrm{evidence})}$$

% TODO: add examples below

$\bullet$ \textbf{Deductive Inference}: from general to specific.

$\bullet$ \textbf{Inductive Inference}: from specific to general.

% Simple induction, analogical induction

$\bullet$ \textbf{Abductive Inference}: From incomplete to best prediction. Forming hypotheses to create explanations.

\subsection{Computational Power}

\subsubsection{Planning by using pure logic}

$\bullet$ Example: steps for getting a PhD. "Working backwards" using a chain of events.

is-PhDStudent(x) $\wedge$ pass-Qualifier(x) $\wedge$ pass-Proposal(x) $\wedge$ defend-Dissertation(x) $\rightarrow$ has-PhD(x)\\

Goal: has-PhD(x)

defend(x, dissertation) $\rightarrow$ hasPhD(x)

dissertation-ok(x, committee) $\rightarrow$ defend(x, dissertation)

$\bullet$ A lot of inferences are necessary, the process is monotonic, and the model cannot learn from experience.

\subsubsection{Explaining by abductive inference}

$y$ was waiting for $x$ at a location, but $x$ never showed up. Why?

known(studying(x) $\rightarrow$ forgetful(x))\\
known(forgetful(x) $\rightarrow$ no-show(x))\\
believed(studying(x))\\
$\rightarrow$ no-show(x)

But there are other possibilities ($x$ could have been in an accident, could have been to another event etc.)

% TODO: add notes on learning and language

\subsection{Psychological Plausibility}

$\bullet$ Three views:

\begin{enumerate}[label=(\Alph*)]
    \item Formal logic is an integral part of human reasoning. This view has been defended by Martin Braine and Lance Rips, but breaks with some factually incorrect syllogisms.
    \item Formal logic is distantly related to human reasoning, but the distance doesn't matter, because logic is only used to provide a mathematical analysis of optimal reasoning.
    \item Formal logic is so distant from human reasoning that it's better to pursue other approaches, such as mental models that correspond in structure to the situations they represent. This view has been defended by Johnson-Laird and Byrne.
\end{enumerate}

\subsubsection{Tversky and Kahneman (Rules of Probability example)}

$\bullet$ According to view C, humans tend not to employ logic correctly in scenarios involving rules of probability. For example:

"A person likes to read poetry, watch foreign movies and discuss world politics. How likely is it that this person is a farmer, a college student, or a farmer who is also a college student?"

By probability rules, the least likely of these options would be the last one. However, people tend to (mathematically incorrectly) think the "is a farmer" option is the least likely one.

\subsubsection{Wason Selection Task (Four-card Problem)}

$\bullet$ "If a card has a vowel on one side, then it has an even number on the other side." Which cards must be turned to test this hypothesis?

$\bullet$ Example: cards $A, B, 4, 7$. We flip $A$ and $7$.

$\bullet$ People usually get a wrong answer, but binding cards to real-world situations (e.g.: social rules such as, "to be in a bar, you must be of drinking age") increases the success rate. This is thought by Cheng and Holyoak to be due to people approaching these tasks with \textit{pragmatic reasoning schemas}, instead of pure logic.

$\bullet$ What most people fail to check is the \textit{modus tollens part}: "If a card has an odd number on one side, then it cannot have a vowel on the other side." This is checked by turning over the card with 7.

\subsection{Neurological Plausibility}

$\bullet$ It is hard to analyze low-level brain activity with pure logic.

$\bullet$ Even for higher-level analysis (such as left side vs. right side of the brain), studies have not been able to find a clear-cut distinction between both sides.

$\bullet$ It has been hypothesized that deduction is formal and independent of content, as well as that deductive reasoning is performed in the left side of the brain. Brain scans by Goel et al. of subjects solving syllogisms seemed to support this view, but Johnson-Laird et al. performed studies that showed the right side of the brain are more active in reasoning than calculation.

\chapter{Rules}

\section{Introduction}

$\bullet$ Do we use rules? How do we choose which rules to follow?

$\bullet$ Do rules play a central role in our ability to think?

$\bullet$ Rule: a structure with a particular format. If \textbf{condition}, then \textbf{action}.

\section{Rules vs. Logic}

$\bullet$ Propositional Logic also features statements of the form $p \rightarrow q$.

$\bullet$ However, rules don't necessarily have to be true (as in a guarantee), unlike in formal logic, where the system would break down if there were inconsistencies.

$\bullet$ Logic Theorists (1956): Herbert Simon, Allen Newell, Cliff Shaw. Attempted to take theorems from \textit{Principia Mathematica} and prove them using computers. They were able to prove 38 out of 52, and found new proofs to several theorems.

$\bullet$ Used rules of inference and strategic rules for finding proofs efficiently. Introduced core ideas to AI, with reasoning as search and heuristics.

$\bullet$ Reasoning as search: from a tree where the root is the hypothesis and the goal is a leaf, which deduction to choose?\\ Uses backtracking, progressive deepening, and pruning.

\subsection{Representational Power}

$\bullet$ Rules can represent many different kinds of knowledge. For example: knowledge about the world; how to do things in the world; knowledge about structures (e.g.: grammar).

$\bullet$ Rules introduce a way to get to language.

$\bullet$ Expressiveness: if you have an if-then rule and the "if" part is true, then the "then" part is true too.

$\bullet$ In a rule, the action may be the default case, but exceptions are OK.

$\bullet$ Not as strong as logic, due to possibly having inconsistencies.

\subsection{Computational Power}

$\bullet$ Problem solving: fundamental premise is that thinking involves searching. We attempt to find a path through the state space that gets from the current state to the goal state.

$\bullet$ A large search space can be generated from something as simple as picking which clothes "go with" other clothes.

$\bullet$ "Problem solving, learning and language can be described as a rules-based heuristics search through a complex space."

\subsubsection{Memory (Rule-based heuristic model)}

$\bullet$ Long-term (consolidated): has explicit and implicit parts. Lasts for days, weeks, years. Limit is not known.

$\bullet$ Short-term: lasts seconds to hours. Readily changeable. Limit is believed to be "small."

$\bullet$ Sensory: lasts instants. Is volatile.

$\bullet$ When "sensing" something in the real world, we recall rules from long-term memory and place them temporarily in short-term memory.

% TODO: rule-based planning definition

\subsubsection{Problem solving}

$\bullet$ Rules are not as helpful when deciding between competing plans.

$\bullet$ Balancing sub-goals requires additional knowledge.

$\bullet$ Forward planning: get to the goal efficiently (optimize for progressing to goal.)

$\bullet$ Backward planning: find sub-goals near final goal (optimize for steps taken.)

$\bullet$ Explanation using rules is stating which rules could be used to reach the goal you know.

$\bullet$ Some rules may be innate.

$\bullet$ Rules can be learned by inductive generalization (examples summarized by a rule.)

$\bullet$ Rules can employ chunking, composition and heuristics to make search efficient.

$\bullet$ Rules can be learned by specialization (for example, abducting traffic predictions based on weather conditions.)

$\bullet$ Slow incremental learning: add weight about the usefulness of rule (for example, how many times the rule has correctly "fired".)

$\bullet$ Examples of Chomsky's argument that language is not a learned habit: people can understand a sentence such as "the squirrel was driving the car", even though they have never really seen this situation happen. Also, people learning languages don't know about irregular verbs, and so attempt to use common rules for them.

$\bullet$ For decision making and explanation, rules are not as "good" as logic.

\subsection{Psychological Plausibility}

$\bullet$ Rules work very well in this aspect.

$\bullet$ People can be conditioned to adhere to some rules.

\chapter{Concepts}

\section{Introduction}

\subsection{Origin of Concepts}

$\bullet$ Symbol grounding problem

$\bullet$ Modal and amodal representations

\subsection{Types of Concepts}

$\bullet$ Axiomatic concepts: defined by a formal set of necessary and sufficient conditions (e.g.: the definition of a circle.)

$\bullet$ Prototype concepts: defined by a typical example with overridable properties (e.g.: a chair can have arms or not, be cushioned or not, but still be a chair.) Maximizes the number of attributes shared in the category, while reducing the number of attributes shared with other categories.

$\bullet$ Exemplar concepts: defined by implicit abstractions of a specific member of the category (e.g.: beauty, dog.)

$\bullet$ \textit{Qualia} concepts: subjective properties of experiences. For example, the taste of a specific kind of food, or "the smell of rain."

\subsection{Quantity of Actions and Percepts}

$\bullet$ If we reasoned about every possible action for every percept, there would be more possible actions than atoms in the Universe, and cognition would not be feasible.

$\bullet$ Equivalence classes: $2^n$ percepts $\rightarrow$ concepts $\rightarrow\ 2^m$ actions

\section{Schema}

$\bullet$ A schema allows for inference by slots, default values, inheritance, or spreading activation.

$\bullet$ For example, respectively: a grocery store (\textit{class}) should have cash registers (\textit{slot}), which are by the doors (\textit{default value}). Since a grocery store is part of the "store" class, one should be able to buy things there (\textit{inheritance}). Also, a store should have a parking lot (\textit{spreading activation}).

$\bullet$ A schema can be used to circumscribe the number of possible actions.

\section{Evaluation}

\subsection{Representational Power}

$\bullet$ Very strong, as sequences of actions can be put into scripts (for example, getting into a restaurant, ordering food, eating it, then paying for it.)

$\bullet$ Inheritance capabilities also contribute to representational power.

\subsection{Computational Power}

$\bullet$ Equivalence classes and matching allow for efficient retrieval. An explanation for something seems "automatic" is a matching concept is found.

$\bullet$ Some care has to be taken to avoid "over-matching" situations. For example, the "script" of actions needed to take a commercial flight and to take a train are similar, but not exactly the same.

$\bullet$ Concepts can be innate, learned from experience, or from other concepts. For a mind with several concepts already formed, forming new ones can come from combination, thereby making "learning" faster.

\subsection{Neurological Plausibility}

$\bullet$ Spreading activation is related to the low-level (neural) architecture of the brain.

$\bullet$ Some famous examples of people who have had brain damage provide insights into how their ability to recall concepts changed after the said damage occurred.



\end{document}
